{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to MLOps using ZenML\n",
    "\n",
    "## üåç Overview\n",
    "\n",
    "This repository is a minimalistic MLOps project intended as a starting point to learn how to put ML workflows in production. It features: \n",
    "\n",
    "- A feature engineering pipeline that loads data and prepares it for training.\n",
    "- A training pipeline that loads the preprocessed dataset and trains a model.\n",
    "- A batch inference pipeline that runs predictions on the trained model with new data.\n",
    "\n",
    "Follow along this notebook to understand how you can use ZenML to productionalize your ML workflows!\n",
    "\n",
    "<img src=\"assets/pipelines_overview.png\" alt=\"Pipelines Overview\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Colab\n",
    "\n",
    "You can use Google Colab to see ZenML in action, no signup / installation\n",
    "required!\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/run.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üë∂ Step 0. Install Requirements\n",
    "\n",
    "Let's install ZenML to get started. First we'll install the latest version of\n",
    "ZenML as well as the `sklearn` integration of ZenML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zenml[server] in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (0.50.0)\n",
      "Requirement already satisfied: alembic<1.9.0,>=1.8.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (1.8.1)\n",
      "Requirement already satisfied: azure-mgmt-resource>=21.0.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (23.0.1)\n",
      "Requirement already satisfied: bcrypt==4.0.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (4.0.1)\n",
      "Requirement already satisfied: click<8.1.4,>=8.0.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (8.1.3)\n",
      "Requirement already satisfied: click-params<0.4.0,>=0.3.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (0.3.0)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (2.2.1)\n",
      "Requirement already satisfied: distro<2.0.0,>=1.6.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (1.8.0)\n",
      "Requirement already satisfied: docker<6.2.0,>=6.1.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (6.1.3)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.18 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (3.1.40)\n",
      "Requirement already satisfied: httplib2<0.20,>=0.19.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (0.19.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (2.0.3)\n",
      "Requirement already satisfied: passlib<1.8.0,>=1.7.4 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from passlib[bcrypt]<1.8.0,>=1.7.4->zenml[server]) (1.7.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (5.9.6)\n",
      "Requirement already satisfied: pydantic<1.11,>=1.9.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (1.10.13)\n",
      "Requirement already satisfied: pymysql<1.1.0,>=1.0.2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (1.0.3)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (2.8.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (6.0.1)\n",
      "Requirement already satisfied: rich>=12.0.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from rich[jupyter]>=12.0.0->zenml[server]) (13.7.0)\n",
      "Requirement already satisfied: sqlalchemy_utils==0.38.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (0.38.3)\n",
      "Requirement already satisfied: sqlmodel==0.0.8 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (0.0.8)\n",
      "Requirement already satisfied: Jinja2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (3.1.2)\n",
      "Requirement already satisfied: fastapi<0.100,>=0.75 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (0.99.1)\n",
      "Requirement already satisfied: fastapi-utils<0.3.0,>=0.2.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (0.2.1)\n",
      "Requirement already satisfied: ipinfo>=4.4.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (5.0.0)\n",
      "Requirement already satisfied: orjson<3.9.0,>=3.8.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (3.8.14)\n",
      "Requirement already satisfied: pyjwt==2.7.* in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from pyjwt[crypto]==2.7.*; extra == \"server\"->zenml[server]) (2.7.0)\n",
      "Requirement already satisfied: python-multipart<0.1.0,>=0.0.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from zenml[server]) (0.0.6)\n",
      "Requirement already satisfied: uvicorn>=0.17.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from uvicorn[standard]>=0.17.5; extra == \"server\"->zenml[server]) (0.24.0.post1)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from pyjwt[crypto]==2.7.*; extra == \"server\"->zenml[server]) (41.0.7)\n",
      "Requirement already satisfied: SQLAlchemy>=1.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from sqlalchemy_utils==0.38.3->zenml[server]) (1.4.41)\n",
      "Requirement already satisfied: sqlalchemy2-stubs in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from sqlmodel==0.0.8->zenml[server]) (0.0.2a37)\n",
      "Requirement already satisfied: Mako in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from alembic<1.9.0,>=1.8.1->zenml[server]) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from alembic<1.9.0,>=1.8.1->zenml[server]) (6.8.0)\n",
      "Requirement already satisfied: importlib-resources in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from alembic<1.9.0,>=1.8.1->zenml[server]) (6.1.1)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from azure-mgmt-resource>=21.0.0->zenml[server]) (0.6.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from azure-mgmt-resource>=21.0.0->zenml[server]) (1.1.28)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from azure-mgmt-resource>=21.0.0->zenml[server]) (1.4.0)\n",
      "Requirement already satisfied: validators<0.19,>=0.18 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from click-params<0.4.0,>=0.3.0->zenml[server]) (0.18.2)\n",
      "Requirement already satisfied: packaging>=14.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from docker<6.2.0,>=6.1.0->zenml[server]) (23.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from docker<6.2.0,>=6.1.0->zenml[server]) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from docker<6.2.0,>=6.1.0->zenml[server]) (2.1.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from docker<6.2.0,>=6.1.0->zenml[server]) (1.6.4)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from fastapi<0.100,>=0.75->zenml[server]) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from fastapi<0.100,>=0.75->zenml[server]) (4.8.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from gitpython<4.0.0,>=3.1.18->zenml[server]) (4.0.11)\n",
      "Requirement already satisfied: cachetools in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipinfo>=4.4.3->zenml[server]) (5.3.2)\n",
      "Requirement already satisfied: aiohttp<=4 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipinfo>=4.4.3->zenml[server]) (3.9.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from pandas>=1.1.5->zenml[server]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from pandas>=1.1.5->zenml[server]) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from pandas>=1.1.5->zenml[server]) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.8.1->zenml[server]) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from rich>=12.0.0->rich[jupyter]>=12.0.0->zenml[server]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from rich>=12.0.0->rich[jupyter]>=12.0.0->zenml[server]) (2.17.2)\n",
      "Requirement already satisfied: ipywidgets<9,>=7.5.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from rich[jupyter]>=12.0.0->zenml[server]) (8.1.1)\n",
      "Requirement already satisfied: h11>=0.8 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from uvicorn>=0.17.5->uvicorn[standard]>=0.17.5; extra == \"server\"->zenml[server]) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from uvicorn[standard]>=0.17.5; extra == \"server\"->zenml[server]) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from uvicorn[standard]>=0.17.5; extra == \"server\"->zenml[server]) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from uvicorn[standard]>=0.17.5; extra == \"server\"->zenml[server]) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from uvicorn[standard]>=0.17.5; extra == \"server\"->zenml[server]) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from uvicorn[standard]>=0.17.5; extra == \"server\"->zenml[server]) (12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from Jinja2->zenml[server]) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<=4->ipinfo>=4.4.3->zenml[server]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<=4->ipinfo>=4.4.3->zenml[server]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<=4->ipinfo>=4.4.3->zenml[server]) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<=4->ipinfo>=4.4.3->zenml[server]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<=4->ipinfo>=4.4.3->zenml[server]) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<=4->ipinfo>=4.4.3->zenml[server]) (4.0.3)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.26.2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from azure-mgmt-core<2.0.0,>=1.3.2->azure-mgmt-resource>=21.0.0->zenml[server]) (1.29.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from cryptography>=3.4.0->pyjwt[crypto]==2.7.*; extra == \"server\"->zenml[server]) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.18->zenml[server]) (5.0.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (8.12.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (5.14.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (3.0.9)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->rich[jupyter]>=12.0.0->zenml[server]) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from requests>=2.26.0->docker<6.2.0,>=6.1.0->zenml[server]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from requests>=2.26.0->docker<6.2.0,>=6.1.0->zenml[server]) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from requests>=2.26.0->docker<6.2.0,>=6.1.0->zenml[server]) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from SQLAlchemy>=1.3->sqlalchemy_utils==0.38.3->zenml[server]) (3.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100,>=0.75->zenml[server]) (4.1.0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from validators<0.19,>=0.18->click-params<0.4.0,>=0.3.0->zenml[server]) (5.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from importlib-metadata->alembic<1.9.0,>=1.8.1->zenml[server]) (3.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100,>=0.75->zenml[server]) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100,>=0.75->zenml[server]) (1.2.0)\n",
      "Requirement already satisfied: pycparser in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]==2.7.*; extra == \"server\"->zenml[server]) (2.21)\n",
      "Requirement already satisfied: backcall in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (3.0.36)\n",
      "Requirement already satisfied: stack-data in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (0.2.12)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.5.1->rich[jupyter]>=12.0.0->zenml[server]) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"zenml[server]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.environment import Environment\n",
    "\n",
    "if Environment.in_google_colab():\n",
    "    # Install Cloudflare Tunnel binary\n",
    "    !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && dpkg -i cloudflared-linux-amd64.deb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m‚†ô\u001b[0m Installing integrations.....Requirement already satisfied: scikit-learn<1.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (1.2.2)\n",
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Installing integrations...Collecting mlflow<=2.6.0,>=2.1.1\n",
      "  Using cached mlflow-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "\u001b[2K\u001b[32m‚†º\u001b[0m Installing integrations...Collecting mlserver>=1.3.3\n",
      "  Using cached mlserver-1.3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "\u001b[2K\u001b[32m‚†¶\u001b[0m Installing integrations...Collecting mlserver-mlflow>=1.3.3\n",
      "  Using cached mlserver_mlflow-1.3.5-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from scikit-learn<1.3) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from scikit-learn<1.3) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from scikit-learn<1.3) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from scikit-learn<1.3) (3.2.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle<3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (2.2.1)\n",
      "\u001b[2K\u001b[32m‚†ß\u001b[0m Installing integrations...Collecting databricks-cli<1,>=0.8.7 (from mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached databricks_cli-0.18.0-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting entrypoints<1 (from mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (3.1.40)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (6.0.1)\n",
      "\u001b[2K\u001b[32m‚†á\u001b[0m Installing integrations...Collecting protobuf<5,>=3.12.0 (from mlflow<=2.6.0,>=2.1.1)\n",
      "\u001b[2K\u001b[32m‚†è\u001b[0m Installing integrations...  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pytz<2024 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (2023.3.post1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (2.31.0)\n",
      "Requirement already satisfied: packaging<24 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (23.2)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (6.8.0)\n",
      "\u001b[2K\u001b[32m‚†ã\u001b[0m Installing integrations...Collecting sqlparse<1,>=0.4.0 (from mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (1.8.1)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (6.1.3)\n",
      "Collecting Flask<3 (from mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached flask-2.3.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pandas<3 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (2.0.3)\n",
      "Collecting querystring-parser<2 (from mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (1.4.41)\n",
      "\u001b[2K\u001b[32m‚†ô\u001b[0m Installing integrations...Collecting pyarrow<13,>=4.0.0 (from mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached pyarrow-12.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "\u001b[2K\u001b[32m‚†π\u001b[0m Installing integrations...Collecting markdown<4,>=3.3 (from mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached Markdown-3.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Installing integrations...Collecting matplotlib<4 (from mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached matplotlib-3.7.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting gunicorn<22 (from mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlflow<=2.6.0,>=2.1.1) (3.1.2)\n",
      "\u001b[2K\u001b[32m‚†º\u001b[0m Installing integrations...Collecting fastapi!=0.89.0,<=0.89.1,>=0.88.0 (from mlserver>=1.3.3)\n",
      "  Using cached fastapi-0.89.1-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: python-dotenv in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlserver>=1.3.3) (1.0.0)\n",
      "\u001b[2K\u001b[32m‚†ß\u001b[0m Installing integrations...Collecting grpcio (from mlserver>=1.3.3)\n",
      "  Using cached grpcio-1.59.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: importlib-resources in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlserver>=1.3.3) (6.1.1)\n",
      "Requirement already satisfied: uvicorn in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlserver>=1.3.3) (0.24.0.post1)\n",
      "Collecting starlette-exporter (from mlserver>=1.3.3)\n",
      "  Using cached starlette_exporter-0.17.1-py3-none-any.whl.metadata (10 kB)\n",
      "\u001b[2K\u001b[32m‚†á\u001b[0m Installing integrations...Collecting py-grpc-prometheus (from mlserver>=1.3.3)\n",
      "  Using cached py_grpc_prometheus-0.7.0-py3-none-any.whl (12 kB)\n",
      "Collecting aiokafka (from mlserver>=1.3.3)\n",
      "  Using cached aiokafka-0.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "\u001b[2K\u001b[32m‚†è\u001b[0m Installing integrations...Collecting tritonclient>=2.24 (from tritonclient[http]>=2.24->mlserver>=1.3.3)\n",
      "  Using cached tritonclient-2.40.0-py3-none-manylinux1_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting aiofiles (from mlserver>=1.3.3)\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: orjson in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlserver>=1.3.3) (3.8.14)\n",
      "Requirement already satisfied: uvloop in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from mlserver>=1.3.3) (0.19.0)\n",
      "Requirement already satisfied: Mako in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow<=2.6.0,>=2.1.1) (1.3.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow<=2.6.0,>=2.1.1) (2.7.0)\n",
      "\u001b[2K\u001b[32m‚†ã\u001b[0m Installing integrations...Collecting oauthlib>=3.1.0 (from databricks-cli<1,>=0.8.7->mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting tabulate>=0.7.7 (from databricks-cli<1,>=0.8.7->mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow<=2.6.0,>=2.1.1) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.7 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow<=2.6.0,>=2.1.1) (2.1.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from docker<7,>=4.0.0->mlflow<=2.6.0,>=2.1.1) (1.6.4)\n",
      "\u001b[2K\u001b[32m‚†ô\u001b[0m Installing integrations...Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from fastapi!=0.89.0,<=0.89.1,>=0.88.0->mlserver>=1.3.3) (1.10.13)\n",
      "Collecting starlette==0.22.0 (from fastapi!=0.89.0,<=0.89.1,>=0.88.0->mlserver>=1.3.3)\n",
      "  Using cached starlette-0.22.0-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from starlette==0.22.0->fastapi!=0.89.0,<=0.89.1,>=0.88.0->mlserver>=1.3.3) (4.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from starlette==0.22.0->fastapi!=0.89.0,<=0.89.1,>=0.88.0->mlserver>=1.3.3) (4.8.0)\n",
      "\u001b[2K\u001b[32m‚†π\u001b[0m Installing integrations...Collecting Werkzeug>=2.3.7 (from Flask<3->mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask<3->mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask<3->mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from gitpython<4,>=2.1.0->mlflow<=2.6.0,>=2.1.1) (4.0.11)\n",
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Installing integrations...Requirement already satisfied: zipp>=0.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow<=2.6.0,>=2.1.1) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from Jinja2<4,>=2.11->mlflow<=2.6.0,>=2.1.1) (2.1.3)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "\u001b[2K\u001b[32m‚†º\u001b[0m Installing integrations...Collecting cycler>=0.10 (from matplotlib<4->mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "\u001b[2K\u001b[32m‚†¥\u001b[0m Installing integrations...Collecting fonttools>=4.22.0 (from matplotlib<4->mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached fonttools-4.46.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (156 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib<4->mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "\u001b[2K\u001b[32m‚†ß\u001b[0m Installing integrations...Collecting pillow>=6.2.0 (from matplotlib<4->mlflow<=2.6.0,>=2.1.1)\n",
      "  Using cached Pillow-10.1.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from matplotlib<4->mlflow<=2.6.0,>=2.1.1) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from matplotlib<4->mlflow<=2.6.0,>=2.1.1) (2.8.2)\n",
      "\u001b[2K\u001b[32m‚†á\u001b[0m Installing integrations...Requirement already satisfied: tzdata>=2022.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from pandas<3->mlflow<=2.6.0,>=2.1.1) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow<=2.6.0,>=2.1.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow<=2.6.0,>=2.1.1) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow<=2.6.0,>=2.1.1) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from sqlalchemy<3,>=1.4.0->mlflow<=2.6.0,>=2.1.1) (3.0.1)\n",
      "\u001b[2K\u001b[32m‚†è\u001b[0m Installing integrations...Collecting python-rapidjson>=0.9.1 (from tritonclient>=2.24->tritonclient[http]>=2.24->mlserver>=1.3.3)\n",
      "  Using cached python_rapidjson-1.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from tritonclient[http]>=2.24->mlserver>=1.3.3) (3.9.1)\n",
      "\u001b[2K\u001b[32m‚†ã\u001b[0m Installing integrations...Collecting geventhttpclient<=2.0.2,>=1.4.4 (from tritonclient[http]>=2.24->mlserver>=1.3.3)\n",
      "  Using cached geventhttpclient-2.0.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (100 kB)\n",
      "Requirement already satisfied: async-timeout in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiokafka->mlserver>=1.3.3) (4.0.3)\n",
      "Requirement already satisfied: setuptools>=39.0.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from py-grpc-prometheus->mlserver>=1.3.3) (68.2.2)\n",
      "Requirement already satisfied: prometheus-client>=0.3.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from py-grpc-prometheus->mlserver>=1.3.3) (0.19.0)\n",
      "\u001b[2K\u001b[32m‚†ô\u001b[0m Installing integrations...Requirement already satisfied: h11>=0.8 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from uvicorn->mlserver>=1.3.3) (0.14.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.1->tritonclient[http]>=2.24->mlserver>=1.3.3) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.1->tritonclient[http]>=2.24->mlserver>=1.3.3) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.1->tritonclient[http]>=2.24->mlserver>=1.3.3) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.1->tritonclient[http]>=2.24->mlserver>=1.3.3) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.1->tritonclient[http]>=2.24->mlserver>=1.3.3) (1.3.1)\n",
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Installing integrations...Collecting gevent>=0.13 (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]>=2.24->mlserver>=1.3.3)\n",
      "  Using cached gevent-23.9.1-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting brotli (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]>=2.24->mlserver>=1.3.3)\n",
      "  Using cached Brotli-1.1.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow<=2.6.0,>=2.1.1) (5.0.1)\n",
      "\u001b[2K\u001b[32m‚†¥\u001b[0m Installing integrations...Requirement already satisfied: sniffio>=1.1 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi!=0.89.0,<=0.89.1,>=0.88.0->mlserver>=1.3.3) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/htahir1/.virtualenvs/templatestarter/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi!=0.89.0,<=0.89.1,>=0.88.0->mlserver>=1.3.3) (1.2.0)\n",
      "\u001b[2K\u001b[32m‚†¶\u001b[0m Installing integrations...Collecting zope.event (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]>=2.24->mlserver>=1.3.3)\n",
      "  Using cached zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "\u001b[2K\u001b[32m‚†ß\u001b[0m Installing integrations...Collecting zope.interface (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]>=2.24->mlserver>=1.3.3)\n",
      "  Using cached zope.interface-6.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K\u001b[32m‚†á\u001b[0m Installing integrations...Using cached mlflow-2.6.0-py3-none-any.whl (18.3 MB)\n",
      "Using cached mlserver-1.3.5-py3-none-any.whl (113 kB)\n",
      "Using cached mlserver_mlflow-1.3.5-py3-none-any.whl (10 kB)\n",
      "Using cached databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
      "Using cached flask-2.3.3-py3-none-any.whl (96 kB)\n",
      "Using cached gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "Using cached Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K\u001b[32m‚†è\u001b[0m Installing integrations...Using cached matplotlib-3.7.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyarrow-12.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.0 MB)\n",
      "\u001b[2K\u001b[32m‚†ô\u001b[0m Installing integrations...Using cached tritonclient-2.40.0-py3-none-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[2K\u001b[32m‚†π\u001b[0m Installing integrations...Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiokafka-0.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached grpcio-1.59.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "Using cached starlette_exporter-0.17.1-py3-none-any.whl (14 kB)\n",
      "Using cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.46.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Using cached kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "Using cached Pillow-10.1.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Installing integrations...Using cached python_rapidjson-1.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Using cached gevent-23.9.1-cp38-cp38-manylinux_2_28_x86_64.whl (6.5 MB)\n",
      "Using cached Brotli-1.1.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
      "Using cached zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
      "Using cached zope.interface-6.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n",
      "\u001b[2K\u001b[32m‚†ã\u001b[0m Installing integrations...Installing collected packages: brotli, zope.interface, zope.event, Werkzeug, tabulate, sqlparse, querystring-parser, python-rapidjson, pyarrow, protobuf, pillow, oauthlib, kiwisolver, itsdangerous, gunicorn, grpcio, fonttools, entrypoints, cycler, contourpy, blinker, aiokafka, aiofiles, tritonclient, starlette, py-grpc-prometheus, matplotlib, markdown, gevent, Flask, databricks-cli, starlette-exporter, mlflow, geventhttpclient, fastapi, mlserver, mlserver-mlflow\n",
      "\u001b[2K\u001b[32m‚†∏\u001b[0m Installing integrations...  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.1\n",
      "\u001b[2K\u001b[32m‚†º\u001b[0m Installing integrations...    Uninstalling pyarrow-14.0.1:\n",
      "      Successfully uninstalled pyarrow-14.0.1\n",
      "\u001b[2K\u001b[32m‚†è\u001b[0m Installing integrations...  Attempting uninstall: starlette\n",
      "    Found existing installation: starlette 0.27.0\n",
      "    Uninstalling starlette-0.27.0:\n",
      "      Successfully uninstalled starlette-0.27.0\n",
      "\u001b[2K\u001b[32m‚†ã\u001b[0m Installing integrations...  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.99.1\n",
      "    Uninstalling fastapi-0.99.1:\n",
      "      Successfully uninstalled fastapi-0.99.1\n",
      "\u001b[2K\u001b[32m‚†π\u001b[0m Installing integrations...Successfully installed Flask-2.3.3 Werkzeug-3.0.1 aiofiles-23.2.1 aiokafka-0.9.0 blinker-1.7.0 brotli-1.1.0 contourpy-1.1.1 cycler-0.12.1 databricks-cli-0.18.0 entrypoints-0.4 fastapi-0.89.1 fonttools-4.46.0 gevent-23.9.1 geventhttpclient-2.0.2 grpcio-1.59.3 gunicorn-21.2.0 itsdangerous-2.1.2 kiwisolver-1.4.5 markdown-3.5.1 matplotlib-3.7.4 mlflow-2.6.0 mlserver-1.3.5 mlserver-mlflow-1.3.5 oauthlib-3.2.2 pillow-10.1.0 protobuf-4.25.1 py-grpc-prometheus-0.7.0 pyarrow-12.0.1 python-rapidjson-1.13 querystring-parser-1.2.4 sqlparse-0.4.4 starlette-0.22.0 starlette-exporter-0.17.1 tabulate-0.9.0 tritonclient-2.40.0 zope.event-5.0 zope.interface-6.1\n",
      "\u001b[2K\u001b[32m‚†¶\u001b[0m Installing integrations...\n",
      "\u001b[1A\u001b[2K"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!zenml integration install sklearn mlflow -y\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please wait for the installation to complete before running subsequent cells. At\n",
    "the end of the installation, the notebook kernel will automatically restart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: If you are using ZenML Cloud, execute the following cell with your tenant URL. Otherwise ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zenml_server_url = \"PLEASE_UPDATE_ME\"  # in the form \"https://URL_TO_SERVER\"\n",
    "\n",
    "!zenml connect --url $zenml_server_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081d5616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[2;36mFound existing ZenML repository at path \u001b[0m\n",
      "\u001b[2;32m'/home/htahir1/workspace/zenml_io/template-starter/template'\u001b[0m\u001b[2;36m.\u001b[0m\n",
      "\u001b[2;32m‚†ã\u001b[0m\u001b[2;36m Initializing ZenML repository at \u001b[0m\n",
      "\u001b[2;36m/home/htahir1/workspace/zenml_io/template-starter/template.\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m‚†ã\u001b[0m Initializing ZenML repository at \n",
      "/home/htahir1/workspace/zenml_io/template-starter/template.\n",
      "\n",
      "\u001b[2K\u001b[2;36mActive repository stack set to: \u001b[0m\u001b[2;32m'default'\u001b[0mive stack to 'default'...\n",
      "\u001b[2K\u001b[32m‚†ô\u001b[0m Setting the repository active stack to 'default'...t'...\u001b[0m\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "# Initialize ZenML and set the default stack\n",
    "!zenml init\n",
    "\n",
    "!zenml stack set default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79f775f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the imports at the top\n",
    "import random\n",
    "from zenml import ExternalArtifact, pipeline, ModelVersion \n",
    "from zenml.client import Client\n",
    "from zenml.logger import get_logger\n",
    "from uuid import UUID\n",
    "\n",
    "import os\n",
    "from typing import Optional, List\n",
    "\n",
    "from zenml import pipeline\n",
    "\n",
    "from steps import (\n",
    "    data_loader,\n",
    "    data_preprocessor,\n",
    "    data_splitter,\n",
    "    model_evaluator,\n",
    "    model_trainer,\n",
    "    inference_predict,\n",
    "    inference_preprocessor\n",
    ")\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•á Step 1: Load your data and execute feature engineering\n",
    "\n",
    "We'll start off by importing our data. In this quickstart we'll be working with\n",
    "[the Breast Cancer](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic) dataset\n",
    "which is publicly available on the UCI Machine Learning Repository. The task is a classification\n",
    "problem, to predict whether a patient is diagnosed with breast cancer or not.\n",
    "\n",
    "When you're getting started with a machine learning problem you'll want to do\n",
    "something similar to this: import your data and get it in the right shape for\n",
    "your training. ZenML mostly gets out of your way when you're writing your Python\n",
    "code, as you'll see from the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from typing_extensions import Annotated\n",
    "from zenml import step\n",
    "from zenml.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "@step\n",
    "def data_loader_simplified(\n",
    "    random_state: int, is_inference: bool = False, target: str = \"target\"\n",
    ") -> Annotated[pd.DataFrame, \"dataset\"]:  # We name the dataset \n",
    "    \"\"\"Dataset reader step.\"\"\"\n",
    "    dataset = load_breast_cancer(as_frame=True)\n",
    "    inference_size = int(len(dataset.target) * 0.05)\n",
    "    dataset: pd.DataFrame = dataset.frame\n",
    "    inference_subset = dataset.sample(inference_size, random_state=random_state)\n",
    "    if is_inference:\n",
    "        dataset = inference_subset\n",
    "        dataset.drop(columns=target, inplace=True)\n",
    "    else:\n",
    "        dataset.drop(inference_subset.index, inplace=True)\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "    logger.info(f\"Dataset with {len(dataset)} records loaded!\")\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole function is decorated with the `@step` decorator, which\n",
    "tells ZenML to track this function as a step in the pipeline. This means that\n",
    "ZenML will automatically version, track, and cache the data that is produced by\n",
    "this function as an `artifact`. This is a very powerful feature, as it means that you can\n",
    "reproduce your data at any point in the future, even if the original data source\n",
    "changes or disappears. \n",
    "\n",
    "Note the use of the `typing` module's `Annotated` type hint in the output of the\n",
    "step. We're using this to give a name to the output of the step, which will make\n",
    "it possible to access it via a keyword later on.\n",
    "\n",
    "You'll also notice that we have included type hints for the outputs\n",
    "to the function. These are not only useful for anyone reading your code, but\n",
    "help ZenML process your data in a way appropriate to the specific data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZenML is built in a way that allows you to experiment with your data and build\n",
    "your pipelines as you work, so if you want to call this function to see how it\n",
    "works, you can just call it directly. Here we take a look at the first few rows\n",
    "of your training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mDataset with 541 records loaded!\u001b[0m\n",
      "\u001b[1;35mDataset with 541 records loaded!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_simplified(random_state=42).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks as we'd expect and the values are all in the right format ü•≥.\n",
    "\n",
    "We're now at the point where can bring all this step and some others together into a single\n",
    "pipeline, the top-level organising entity for code in ZenML. Creating such a pipeline is\n",
    "as simple as adding a `@pipeline` decorator to a function. This specific\n",
    "pipeline doesn't return a value, but that option is available to you if you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b50a9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def feature_engineering(\n",
    "    test_size: float = 0.2,\n",
    "    drop_na: Optional[bool] = None,\n",
    "    normalize: Optional[bool] = None,\n",
    "    drop_columns: Optional[List[str]] = None,\n",
    "    target: Optional[str] = \"target\",\n",
    "):\n",
    "    \"\"\"Feature engineering pipeline.\"\"\"\n",
    "    # Link all the steps together by calling them and passing the output\n",
    "    # of one step as the input of the next step.\n",
    "    raw_data = data_loader(random_state=random.randint(0, 100), target=target)\n",
    "    dataset_trn, dataset_tst = data_splitter(\n",
    "        dataset=raw_data,\n",
    "        test_size=test_size,\n",
    "    )\n",
    "    dataset_trn, dataset_tst, _ = data_preprocessor(\n",
    "        dataset_trn=dataset_trn,\n",
    "        dataset_tst=dataset_tst,\n",
    "        drop_na=drop_na,\n",
    "        normalize=normalize,\n",
    "        drop_columns=drop_columns,\n",
    "        target=target,\n",
    "    )\n",
    "    \n",
    "    return dataset_trn, dataset_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to run the pipeline now, which we can do just -- as with the step -- by calling the\n",
    "pipeline function itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mfeature_engineering\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mReusing registered version: \u001b[0m\u001b[1;36m(version: 3)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mhamza@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mDataset with 541 records loaded!\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m has finished in \u001b[0m\u001b[1;36m1.950s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m has finished in \u001b[0m\u001b[1;36m3.650s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m has finished in \u001b[0m\u001b[1;36m4.506s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mRun \u001b[0m\u001b[1;36mfeature_engineering-2023_12_07-16_50_18_998605\u001b[1;35m has finished in \u001b[0m\u001b[1;36m13.591s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://1cf18d95-zenml.cloudinfra.zenml.io/workspaces/default/pipelines/84da85e1-956e-4d47-8719-9ee1c3335ab5/runs/80ccff19-b000-434d-84f8-b93fd8cfbc45/dag\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "feature_engineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this again with a slightly different test size, to create another dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mfeature_engineering\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mReusing registered version: \u001b[0m\u001b[1;36m(version: 4)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mhamza@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m has finished in \u001b[0m\u001b[1;36m3.236s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m has finished in \u001b[0m\u001b[1;36m4.466s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mRun \u001b[0m\u001b[1;36mfeature_engineering-2023_12_07-16_50_36_291181\u001b[1;35m has finished in \u001b[0m\u001b[1;36m10.784s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://1cf18d95-zenml.cloudinfra.zenml.io/workspaces/default/pipelines/739a6ab3-b209-4947-8cc1-c3aafa4d9718/runs/ee337da9-e510-49df-957c-333b24cdf0b8/dag\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "feature_engineering(test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the data loader step was cached, while the rest of the pipeline was rerun. \n",
    "This is because ZenML automatically determined that nothing had changed in the data loader step, \n",
    "so it didn't need to rerun it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you might be interested to view your pipeline runs in the ZenML\n",
    "Dashboard. You can spin this up by executing the next cell. This will start a\n",
    "server which you can access by clicking on the link that appears in the output\n",
    "of the cell.\n",
    "\n",
    "Log into the Dashboard using default credentials (username 'default' and\n",
    "password left blank). From there you can inspect the pipeline or the specific\n",
    "pipeline run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \u001b[31m\u001b[1mYour ZenML client is already connected to a remote server. If you want to spin up a local ZenML server, please disconnect from the remote server first by running `zenml disconnect`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from zenml.environment import Environment\n",
    "\n",
    "if Environment.in_google_colab():\n",
    "    # run ZenML through a cloudflare tunnel to get a public endpoint\n",
    "    !zenml up --port 8237 & cloudflared tunnel --url http://localhost:8237\n",
    "else:\n",
    "    !zenml up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also fetch the pipeline from the server and view our results directly in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_engineering-2023_12_07-16_50_36_291181\n"
     ]
    }
   ],
   "source": [
    "client = Client()\n",
    "run = client.get_pipeline(\"feature_engineering\").last_run\n",
    "print(run.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the data artifacts that were produced by the last step of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_tst': ArtifactResponse(id=UUID('77b1c2eb-c9bd-4030-b42c-21d06927d2b9'), permission_denied=False, body=ArtifactResponseBody(created=datetime.datetime(2023, 12, 7, 16, 50, 45), updated=datetime.datetime(2023, 12, 7, 16, 50, 45), user=UserResponse(id=UUID('c6fcdcc8-69e1-4ff5-9eb2-6a53aa81a08b'), permission_denied=False, body=UserResponseBody(created=datetime.datetime(2023, 10, 24, 7, 36, 26), updated=datetime.datetime(2023, 12, 7, 16, 6, 42), active=True, activation_token=None, full_name='Hamza Tahir', email_opted_in=True, is_service_account=False), metadata=None, name='hamza@zenml.io'), version='80', uri='/home/htahir1/.config/zenml/local_stores/466b79ce-3df9-4549-a50b-67ed433461f3/data_preprocessor/dataset_tst/b277e9ac-2631-4038-86f5-a71b7da09104', type=<ArtifactType.DATA: 'DataArtifact'>), metadata=None, name='dataset_tst'),\n",
       " 'dataset_trn': ArtifactResponse(id=UUID('92cbfbef-0bf7-4247-9448-73c429465b82'), permission_denied=False, body=ArtifactResponseBody(created=datetime.datetime(2023, 12, 7, 16, 50, 44), updated=datetime.datetime(2023, 12, 7, 16, 50, 44), user=UserResponse(id=UUID('c6fcdcc8-69e1-4ff5-9eb2-6a53aa81a08b'), permission_denied=False, body=UserResponseBody(created=datetime.datetime(2023, 10, 24, 7, 36, 26), updated=datetime.datetime(2023, 12, 7, 16, 6, 42), active=True, activation_token=None, full_name='Hamza Tahir', email_opted_in=True, is_service_account=False), metadata=None, name='hamza@zenml.io'), version='82', uri='/home/htahir1/.config/zenml/local_stores/466b79ce-3df9-4549-a50b-67ed433461f3/data_preprocessor/dataset_trn/b277e9ac-2631-4038-86f5-a71b7da09104', type=<ArtifactType.DATA: 'DataArtifact'>), metadata=None, name='dataset_trn'),\n",
       " 'preprocess_pipeline': ArtifactResponse(id=UUID('bf3fd112-e5d0-4c0a-aaff-18307b2401fe'), permission_denied=False, body=ArtifactResponseBody(created=datetime.datetime(2023, 12, 7, 16, 50, 46), updated=datetime.datetime(2023, 12, 7, 16, 50, 46), user=UserResponse(id=UUID('c6fcdcc8-69e1-4ff5-9eb2-6a53aa81a08b'), permission_denied=False, body=UserResponseBody(created=datetime.datetime(2023, 10, 24, 7, 36, 26), updated=datetime.datetime(2023, 12, 7, 16, 6, 42), active=True, activation_token=None, full_name='Hamza Tahir', email_opted_in=True, is_service_account=False), metadata=None, name='hamza@zenml.io'), version='80', uri='/home/htahir1/.config/zenml/local_stores/466b79ce-3df9-4549-a50b-67ed433461f3/data_preprocessor/preprocess_pipeline/b277e9ac-2631-4038-86f5-a71b7da09104', type=<ArtifactType.MODEL: 'ModelArtifact'>), metadata=None, name='preprocess_pipeline')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.steps[\"data_preprocessor\"].outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for DistributionPackageSource\npackage_name\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/htahir1/workspace/zenml_io/template-starter/template/run.ipynb Cell 30\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/htahir1/workspace/zenml_io/template-starter/template/run.ipynb#Y206sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Read one of the datasets:\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/htahir1/workspace/zenml_io/template-starter/template/run.ipynb#Y206sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m run\u001b[39m.\u001b[39;49msteps[\u001b[39m\"\u001b[39;49m\u001b[39mdata_preprocessor\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49moutputs[\u001b[39m\"\u001b[39;49m\u001b[39mdataset_trn\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[0;32m~/.virtualenvs/templatestarter/lib/python3.8/site-packages/zenml/models/v2/core/artifact.py:306\u001b[0m, in \u001b[0;36mArtifactResponse.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Materializes (loads) the data stored in this artifact.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[39m    The materialized data.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mzenml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39martifacts\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_artifact_from_response\n\u001b[0;32m--> 306\u001b[0m \u001b[39mreturn\u001b[39;00m load_artifact_from_response(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/.virtualenvs/templatestarter/lib/python3.8/site-packages/zenml/artifacts/utils.py:381\u001b[0m, in \u001b[0;36mload_artifact_from_response\u001b[0;34m(artifact)\u001b[0m\n\u001b[1;32m    373\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    374\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to restore artifact store while trying to load artifact \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m`. If this artifact is stored in a remote artifact store, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthis might lead to issues when trying to load the artifact.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    377\u001b[0m         artifact\u001b[39m.\u001b[39mid,\n\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    380\u001b[0m \u001b[39m# breakpoint()\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m _load_artifact_from_uri(\n\u001b[1;32m    382\u001b[0m     materializer\u001b[39m=\u001b[39;49martifact\u001b[39m.\u001b[39;49mmaterializer,\n\u001b[1;32m    383\u001b[0m     data_type\u001b[39m=\u001b[39;49martifact\u001b[39m.\u001b[39;49mdata_type,\n\u001b[1;32m    384\u001b[0m     uri\u001b[39m=\u001b[39;49martifact\u001b[39m.\u001b[39;49muri,\n\u001b[1;32m    385\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/templatestarter/lib/python3.8/site-packages/zenml/artifacts/utils.py:468\u001b[0m, in \u001b[0;36m_load_artifact_from_uri\u001b[0;34m(materializer, data_type, uri)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[39m# Resolve the artifact class\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     \u001b[39m# breakpoint()\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m     artifact_class \u001b[39m=\u001b[39m source_utils\u001b[39m.\u001b[39;49mload(data_type)\n\u001b[1;32m    469\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     logger\u001b[39m.\u001b[39merror(\n\u001b[1;32m    471\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mZenML cannot locate and import the data type of this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    472\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39martifact \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdata_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/templatestarter/lib/python3.8/site-packages/zenml/utils/source_utils.py:75\u001b[0m, in \u001b[0;36mload\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     73\u001b[0m     import_root \u001b[39m=\u001b[39m get_source_root()\n\u001b[1;32m     74\u001b[0m \u001b[39melif\u001b[39;00m source\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m SourceType\u001b[39m.\u001b[39mDISTRIBUTION_PACKAGE:\n\u001b[0;32m---> 75\u001b[0m     source \u001b[39m=\u001b[39m DistributionPackageSource\u001b[39m.\u001b[39;49mparse_obj(source)\n\u001b[1;32m     76\u001b[0m     \u001b[39mif\u001b[39;00m source\u001b[39m.\u001b[39mversion:\n\u001b[1;32m     77\u001b[0m         current_package_version \u001b[39m=\u001b[39m _get_package_version(\n\u001b[1;32m     78\u001b[0m             package_name\u001b[39m=\u001b[39msource\u001b[39m.\u001b[39mpackage_name\n\u001b[1;32m     79\u001b[0m         )\n",
      "File \u001b[0;32m~/.virtualenvs/templatestarter/lib/python3.8/site-packages/pydantic/main.py:526\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.parse_obj\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/templatestarter/lib/python3.8/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for DistributionPackageSource\npackage_name\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "# Read one of the datasets. This is the one with a 0.3 test split\n",
    "run.steps[\"data_preprocessor\"].outputs[\"dataset_trn\"].load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the artifacts directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArtifactResponse(id=UUID('92cbfbef-0bf7-4247-9448-73c429465b82'), permission_denied=False, body=ArtifactResponseBody(created=datetime.datetime(2023, 12, 7, 16, 50, 44), updated=datetime.datetime(2023, 12, 7, 16, 50, 44), user=UserResponse(id=UUID('c6fcdcc8-69e1-4ff5-9eb2-6a53aa81a08b'), permission_denied=False, body=UserResponseBody(created=datetime.datetime(2023, 10, 24, 7, 36, 26), updated=datetime.datetime(2023, 12, 7, 16, 6, 42), active=True, activation_token=None, full_name='Hamza Tahir', email_opted_in=True, is_service_account=False), metadata=None, name='hamza@zenml.io'), version='82', uri='/home/htahir1/.config/zenml/local_stores/466b79ce-3df9-4549-a50b-67ed433461f3/data_preprocessor/dataset_trn/b277e9ac-2631-4038-86f5-a71b7da09104', type=<ArtifactType.DATA: 'DataArtifact'>), metadata=None, name='dataset_trn')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_trn_artifact = client.get_artifact(\"dataset_trn\")\n",
    "dataset_tst_artifact = client.get_artifact(\"dataset_tst\")\n",
    "\n",
    "dataset_trn_artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use these artifacts from above in our next pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚åö Step 2: Training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data it makes sense to train some models to get a sense of\n",
    "how difficult the task is. The Breast Cancer dataset is sufficiently large and complex \n",
    "that it's unlikely we'll be able to train a model that behaves perfectly since the problem \n",
    "is inherently complex, but we can get a sense of what a reasonable baseline looks like.\n",
    "\n",
    "We'll start with two simple models, a SGD Classifier and a Random Forest\n",
    "Classifier, both batteries-included from `sklearn`. We'll train them both on the\n",
    "same data and then compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from typing_extensions import Annotated\n",
    "from zenml import ArtifactConfig, step\n",
    "from zenml.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "@step\n",
    "def model_trainer(\n",
    "    dataset_trn: pd.DataFrame,\n",
    "    model_type: str = \"sgd\",\n",
    ") -> Annotated[ClassifierMixin, ArtifactConfig(name=\"model\", is_model_artifact=True)]:\n",
    "    \"\"\"Configure and train a model on the training dataset.\"\"\"\n",
    "    target = \"target\"\n",
    "    if model_type == \"sgd\":\n",
    "        model = SGDClassifier()\n",
    "    elif model_type == \"rf\":\n",
    "        model = RandomForestClassifier()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type {model_type}\")   \n",
    "\n",
    "    logger.info(f\"Training model {model}...\")\n",
    "\n",
    "    model.fit(\n",
    "        dataset_trn.drop(columns=[target]),\n",
    "        dataset_trn[target],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our two training steps both return different kinds of `sklearn` classifier\n",
    "models, so we use the generic `ClassifierMixin` type hint for the return type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZenML allows you to load any version of any dataset that is tracked by the framework\n",
    "directly into a pipeline using the `ExternalArtifact` interface. This is very convenient\n",
    "in this case, as we'd like to send our preprocessed dataset from the older pipeline directly\n",
    "into the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def training(\n",
    "    train_dataset_id: Optional[UUID] = None,\n",
    "    test_dataset_id: Optional[UUID] = None,\n",
    "    model_type: str = \"sgd\",\n",
    "    min_train_accuracy: float = 0.0,\n",
    "    min_test_accuracy: float = 0.0,\n",
    "):\n",
    "    \"\"\"Model training pipeline.\"\"\" \n",
    "    if train_dataset_id is None or test_dataset_id is None:\n",
    "        # If we dont pass the IDs, this will run the feature engineering pipeline   \n",
    "        dataset_trn, dataset_tst = feature_engineering()\n",
    "    else:\n",
    "        # Load the datasets from an older pipeline\n",
    "        dataset_trn = ExternalArtifact(id=train_dataset_id)\n",
    "        dataset_tst = ExternalArtifact(id=test_dataset_id) \n",
    "\n",
    "    trained_model = model_trainer(\n",
    "        dataset_trn=dataset_trn,\n",
    "        model_type=model_type,\n",
    "    )\n",
    "\n",
    "    model_evaluator(\n",
    "        model=trained_model,\n",
    "        dataset_trn=dataset_trn,\n",
    "        dataset_tst=dataset_tst,\n",
    "        min_train_accuracy=min_train_accuracy,\n",
    "        min_test_accuracy=min_test_accuracy,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end goal of this quick baseline evaluation is to understand which of the two\n",
    "models performs better. We'll use the `evaluator` step to compare the two\n",
    "models. This step takes in the model from the trainer step, and computes its score\n",
    "over the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mtraining\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mRegistered new version: \u001b[0m\u001b[1;36m(version 13)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mhamza@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mTraining model RandomForestClassifier()...\u001b[0m\n",
      "\u001b[1;35mTraining model RandomForestClassifier()...\u001b[0m\n",
      "\u001b[1;35mTraining model RandomForestClassifier()...\u001b[0m\n",
      "\u001b[1;35mTraining model RandomForestClassifier()...\u001b[0m\n",
      "\u001b[1;35mTraining model RandomForestClassifier()...\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has finished in \u001b[0m\u001b[1;36m2.695s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mTrain accuracy=100.00%\u001b[0m\n",
      "\u001b[1;35mTest accuracy=95.71%\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m has finished in \u001b[0m\u001b[1;36m3.661s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mRun \u001b[0m\u001b[1;36mtraining-2023_12_07-17_07_26_910917\u001b[1;35m has finished in \u001b[0m\u001b[1;36m10.706s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://1cf18d95-zenml.cloudinfra.zenml.io/workspaces/default/pipelines/c5622964-5dae-488c-a3d8-8564f4b47e30/runs/bae238a7-7df5-407b-a70a-6ed3ddcd2d60/dag\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Use a random forest model\n",
    "training(model_type=\"rf\", train_dataset_id=dataset_trn_artifact.id, test_dataset_id=dataset_tst_artifact.id)\n",
    "\n",
    "rf_run = client.get_pipeline(\"training\").last_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mtraining\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mRegistered new version: \u001b[0m\u001b[1;36m(version 14)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mhamza@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mTraining model SGDClassifier()...\u001b[0m\n",
      "\u001b[1;35mTraining model SGDClassifier()...\u001b[0m\n",
      "\u001b[1;35mTraining model SGDClassifier()...\u001b[0m\n",
      "\u001b[1;35mTraining model SGDClassifier()...\u001b[0m\n",
      "\u001b[1;35mTraining model SGDClassifier()...\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has finished in \u001b[0m\u001b[1;36m2.781s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mTrain accuracy=87.57%\u001b[0m\n",
      "\u001b[1;35mTest accuracy=90.18%\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m has finished in \u001b[0m\u001b[1;36m3.756s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mRun \u001b[0m\u001b[1;36mtraining-2023_12_07-17_07_43_757223\u001b[1;35m has finished in \u001b[0m\u001b[1;36m11.332s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://1cf18d95-zenml.cloudinfra.zenml.io/workspaces/default/pipelines/ba6e6157-88ba-4347-80bb-89bca2f7fb1b/runs/27dcce8a-3787-4daa-a1bb-e24ebee82bc9/dag\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Use a SGD classifier\n",
    "training(model_type=\"sgd\", train_dataset_id=dataset_trn_artifact.id, test_dataset_id=dataset_tst_artifact.id)\n",
    "\n",
    "sgd_run = client.get_pipeline(\"training\").last_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the logs already how our model training went: the\n",
    "`RandomForestClassifier` performed considerably better than the `SGDClassifier`.\n",
    "We can use the ZenML `Client` to verify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The evaluator returns a float value with the accuracy\n",
    "rf_run.steps[\"model_evaluator\"].output.load() > sgd_run.steps[\"model_evaluator\"].output.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚åö Step 3: Associating a model with your pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see it is relatively easy to train ML models using ZenML pipelines. But it can be somewhat clunky to track\n",
    "all the models produced as you develop your experiments and use-cases. Luckily, ZenML offers a *Model Control Plane*,\n",
    "which is a central register of all your ML models.\n",
    "\n",
    "You can easily create a ZenML Model and associate it with your pipelines using the `ModelVersion` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_settings = {}\n",
    "pipeline_settings[\"model_version\"] = ModelVersion(\n",
    "    name=\"breast_cancer_classifier\",\n",
    "    license=\"Apache 2.0\",\n",
    "    description=\"A breast cancer classifier\",\n",
    "    tags=[\"classification\", \"sklearn\"],\n",
    ")\n",
    "\n",
    "# the `with_options` method allows us to pass in pipeline settings\n",
    "#  and returns a configured pipeline\n",
    "training_configured = training.with_options(**pipeline_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mtraining\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mReusing registered version: \u001b[0m\u001b[1;36m(version: 14)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mNew model version \u001b[0m\u001b[1;36m13\u001b[1;35m was created.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mhamza@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mLinking artifact \u001b[0m\u001b[1;36moutput\u001b[1;35m to model \u001b[0m\u001b[1;36mNone\u001b[1;35m version \u001b[0m\u001b[1;36mNone\u001b[1;35m implicitly.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mRun \u001b[0m\u001b[1;36mtraining-2023_12_07-17_08_57_860304\u001b[1;35m has finished in \u001b[0m\u001b[1;36m6.124s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://1cf18d95-zenml.cloudinfra.zenml.io/workspaces/default/pipelines/ba6e6157-88ba-4347-80bb-89bca2f7fb1b/runs/ce39950a-313c-434c-bc3a-a62f2e5ed4bd/dag\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# We can now run this as usual\n",
    "training_configured(model_type=\"sgd\", train_dataset_id=dataset_trn_artifact.id, test_dataset_id=dataset_tst_artifact.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mtraining\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mReusing registered version: \u001b[0m\u001b[1;36m(version: 13)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mNew model version \u001b[0m\u001b[1;36m14\u001b[1;35m was created.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mhamza@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mLinking artifact \u001b[0m\u001b[1;36moutput\u001b[1;35m to model \u001b[0m\u001b[1;36mNone\u001b[1;35m version \u001b[0m\u001b[1;36mNone\u001b[1;35m implicitly.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mRun \u001b[0m\u001b[1;36mtraining-2023_12_07-17_09_08_682638\u001b[1;35m has finished in \u001b[0m\u001b[1;36m5.989s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://1cf18d95-zenml.cloudinfra.zenml.io/workspaces/default/pipelines/c5622964-5dae-488c-a3d8-8564f4b47e30/runs/85f154cf-675d-45ac-87b3-b36673b63fe7/dag\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# We can now run this as usual\n",
    "training_configured(model_type=\"rf\", train_dataset_id=dataset_trn_artifact.id, test_dataset_id=dataset_tst_artifact.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can list your ZenML model and their versions as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='breast_cancer_classifier' license='Apache 2.0' description='Classification of Breast Cancer Dataset.' audience=None use_cases=None limitations=None trade_offs=None ethics=None id=UUID('952d7089-dac6-4402-874a-89d81e308e33') created=datetime.datetime(2023, 12, 7, 14, 17, 13) updated=datetime.datetime(2023, 12, 7, 14, 17, 13) missing_permissions=False user=UserResponse(id=UUID('c6fcdcc8-69e1-4ff5-9eb2-6a53aa81a08b'), permission_denied=False, body=UserResponseBody(created=datetime.datetime(2023, 10, 24, 7, 36, 26), updated=datetime.datetime(2023, 12, 7, 16, 6, 42), active=True, activation_token=None, full_name='Hamza Tahir', email_opted_in=True, is_service_account=False), metadata=None, name='hamza@zenml.io') workspace=WorkspaceResponse(id=UUID('f3a544f2-afb5-4672-934a-7a465c66201c'), permission_denied=False, body=WorkspaceResponseBody(created=datetime.datetime(2023, 10, 23, 15, 34, 47), updated=datetime.datetime(2023, 10, 23, 15, 34, 47)), metadata=None, name='default') tags=[TagResponseModel(id=UUID('0030e89b-b3a1-4267-a2d8-16fad8a39860'), created=datetime.datetime(2023, 11, 30, 9, 45, 52), updated=datetime.datetime(2023, 11, 30, 9, 45, 52), missing_permissions=False, name='classification', color=<ColorVariants.BLUE: 'blue'>, tagged_count=1), TagResponseModel(id=UUID('e308de9a-819a-4079-8c09-336f55c095c8'), created=datetime.datetime(2023, 11, 30, 9, 45, 52), updated=datetime.datetime(2023, 11, 30, 9, 45, 52), missing_permissions=False, name='sklearn', color=<ColorVariants.BLUE: 'blue'>, tagged_count=1)] latest_version='14'\n",
      "Model breast_cancer_classifier has 14 versions\n"
     ]
    }
   ],
   "source": [
    "client = Client()\n",
    "zenml_model = client.get_model(\"breast_cancer_classifier\")\n",
    "print(zenml_model)\n",
    "\n",
    "print(f\"Model {zenml_model.name} has {len(zenml_model.versions)} versions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a new model version was created when the `training` pipeline was run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_t_configured()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def batch_inference():\n",
    "    \"\"\"\n",
    "    Model batch inference pipeline.\n",
    "\n",
    "    This is a pipeline that loads the inference data, processes\n",
    "    it, analyze for data drift and run inference.\n",
    "    \"\"\"\n",
    "    ### ADD YOUR OWN CODE HERE - THIS IS JUST AN EXAMPLE ###\n",
    "    # Link all the steps together by calling them and passing the output\n",
    "    # of one step as the input of the next step.\n",
    "    ########## ETL stage  ##########\n",
    "    random_state = client.get_artifact(\"dataset\").run_metadata[\"random_state\"].value\n",
    "    target = client.get_artifact(\"dataset_trn\").run_metadata['target'].value\n",
    "    df_inference = data_loader(\n",
    "        random_state=random_state, is_inference=True\n",
    "    )\n",
    "    df_inference = inference_preprocessor(\n",
    "        dataset_inf=df_inference,\n",
    "        preprocess_pipeline=ExternalArtifact(name=\"preprocess_pipeline\"),\n",
    "        target=target,\n",
    "    )\n",
    "    inference_predict(\n",
    "        dataset_inf=df_inference,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_args = {}\n",
    "pipeline_args[\"config_path\"] = os.path.join(\"configs\", \"inference.yaml\")\n",
    "fe_b_configured = batch_inference.with_options(**pipeline_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_b_configured()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc77b660-e206-46b1-a924-407e797a8f47",
   "metadata": {},
   "source": [
    "# üç≥Breaking it down\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de0e4c-b6f8-4b68-927a-f40e4130dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def data_loader() -> Annotated[DatasetDict, \"dataset\"]:\n",
    "    logger.info(f\"Loading dataset airline_reviews... \")\n",
    "    hf_dataset = load_dataset(\"Shayanvsf/US_Airline_Sentiment\")\n",
    "    hf_dataset = hf_dataset.rename_column(\"airline_sentiment\", \"label\")\n",
    "    hf_dataset = hf_dataset.remove_columns(\n",
    "        [\"airline_sentiment_confidence\", \"negativereason_confidence\"]\n",
    "    )\n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e4462c-1e64-48d3-bae7-76696a958646",
   "metadata": {},
   "source": [
    "Notice that you can give each dataset a name with Python‚Äôs Annotated object. The DatasetDict is a native Huggingface dataset which ZenML knows how to persist through steps. This flow ensures reproducibility and version control for every dataset iteration.\n",
    "\n",
    "Also notice this is a simple Python function, that can be called with the `entrypoint` wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18144a6b-c266-453d-82c8-b5d6aa1be0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = data_loader.entrypoint()\n",
    "print(hf_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31330d3c-044f-4912-8d36-74146f48cecf",
   "metadata": {},
   "source": [
    "Now we put this a full feature engineering pipeline. Each run of the feature engineering pipeline produces a new dataset to use for the training pipeline. ZenML versions this data as it flows through the pipeline.\n",
    "\n",
    "<img src=\"assets/pipelines_feature_eng.png\" alt=\"Pipelines Feature Engineering\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9511bd84-1e97-42db-9b75-06285cc6904c",
   "metadata": {},
   "source": [
    "### Set your stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3a7e7-0d85-43b3-9e9f-4c7f20ea65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack describe hf-sagemaker-local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b0bf69-70c6-4408-b18c-95df9e030c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack set hf-sagemaker-local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5398a4-a9ec-42d6-bbd6-390244c52d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f718d-70c2-4a29-a73e-37db85675cb8",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6c41e-e4b3-46d2-8264-9a453ac9aa3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@pipeline(on_failure=notify_on_failure)\n",
    "def sentinment_analysis_feature_engineering_pipeline(\n",
    "    lower_case: Optional[bool] = True,\n",
    "    padding: Optional[str] = \"max_length\",\n",
    "    max_seq_length: Optional[int] = 128,\n",
    "    text_column: Optional[str] = \"text\",\n",
    "    label_column: Optional[str] = \"label\",\n",
    "):\n",
    "    # Link all the steps together by calling them and passing the output\n",
    "    # of one step as the input of the next step.\n",
    "\n",
    "    ########## Load Dataset stage ##########\n",
    "    dataset = data_loader()\n",
    "\n",
    "    ########## Data Quality stage ##########\n",
    "    reference_dataset, comparison_dataset = generate_reference_and_comparison_datasets(\n",
    "        dataset\n",
    "    )\n",
    "    text_data_report = evidently_report_step.with_options(\n",
    "        parameters=dict(\n",
    "            column_mapping=EvidentlyColumnMapping(\n",
    "                target=\"label\",\n",
    "                text_features=[\"text\"],\n",
    "            ),\n",
    "            metrics=[\n",
    "                EvidentlyMetricConfig.metric(\"DataQualityPreset\"),\n",
    "                EvidentlyMetricConfig.metric(\n",
    "                    \"TextOverviewPreset\", column_name=\"text\"\n",
    "                ),\n",
    "            ],\n",
    "            # We need to download the NLTK data for the TextOverviewPreset\n",
    "            download_nltk_data=True,\n",
    "        ),\n",
    "    )\n",
    "    text_data_report(reference_dataset, comparison_dataset)\n",
    "\n",
    "    ########## Tokenization stage ##########\n",
    "    tokenizer = tokenizer_loader(lower_case=lower_case)\n",
    "    tokenized_data = tokenization_step(\n",
    "        dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        padding=padding,\n",
    "        max_seq_length=max_seq_length,\n",
    "        text_column=text_column,\n",
    "        label_column=label_column,\n",
    "    )\n",
    "    return tokenizer, tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a5be7-ebaa-41c4-ac23-4afc6e7e06aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a pipeline with the required parameters. \n",
    "no_cache: bool = True\n",
    "zenml_model_name: str = \"distil_bert_sentiment_analysis\"\n",
    "max_seq_length = 512\n",
    "\n",
    "# This executes all steps in the pipeline in the correct order using the orchestrator\n",
    "# stack component that is configured in your active ZenML stack.\n",
    "model_config = ModelConfig(\n",
    "    name=zenml_model_name,\n",
    "    license=\"Apache 2.0\",\n",
    "    description=\"Show case Model Control Plane.\",\n",
    "    create_new_model_version=True,\n",
    "    delete_new_version_on_failure=True,\n",
    "    tags=[\"sentiment_analysis\", \"huggingface\"],\n",
    ")\n",
    "\n",
    "pipeline_args = {}\n",
    "\n",
    "if no_cache:\n",
    "    pipeline_args[\"enable_cache\"] = False\n",
    "\n",
    "# Execute Feature Engineering Pipeline\n",
    "pipeline_args[\"model_config\"] = model_config\n",
    "pipeline_args[\"config_path\"] = os.path.join(\"configs\", \"feature_engineering_config.yaml\")\n",
    "run_args_feature = {\n",
    "    \"max_seq_length\": max_seq_length,\n",
    "}\n",
    "pipeline_args[\n",
    "    \"run_name\"\n",
    "] = f\"sentinment_analysis_feature_engineering_pipeline_run_{dt.now().strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
    "p = sentinment_analysis_feature_engineering_pipeline.with_options(**pipeline_args)\n",
    "p(**run_args_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c1ea2-64fe-478a-9963-17c7b7f62110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.client import Client\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "client = Client()\n",
    "# CHANGE THIS TO THE LATEST RUN ID\n",
    "latest_run = client.get_pipeline_run(\"sentinment_analysis_feature_engineering_pipeline_run_2023_11_21_10_55_56\")\n",
    "html = latest_run.steps[\"evidently_report_step\"].outputs['report_html'].load()\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab8771-4421-4975-a3d5-12892a56b805",
   "metadata": {},
   "source": [
    "## üí™ Step 2: Train the model with Huggingface Hub as the model registry\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843efa8-32b6-4b13-ac85-33c99cc94e3e",
   "metadata": {},
   "source": [
    "Once the feature engineering pipeline has run a few times, we have many datasets to choose from. We can feed our desired one into a function that trains the model on the data. Thanks to the ZenML Huggingface integration, this data is loaded directly from the ZenML artifact store.\n",
    "\n",
    "<img src=\"assets/training_pipeline_overview.png\" alt=\"Pipelines Trains\">\n",
    "\n",
    "On the left side, we see our local MLOps stack, which defines our infrastructure and tooling we are using for this particular pipeline. ZenML makes it easy to run on a local stack on your development machine, or switch out the stack to run on a AWS Kubeflow-based stack (if you want to scale up).\n",
    "\n",
    "On the right side is the new kid on the block - the ZenML Model Control Plane. The Model Control Plane is a new feature in ZenML that allows users to have a complete overview of their machine learning models. It allows teams to consolidate all artifacts related to their ML models into one place, and manage its lifecycle easily as you can see from this view from the ZenML Cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c99b20f-8e3b-4119-86e9-33dd1395470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_args[\"config_path\"] = os.path.join(\"configs\", \"trainer_config.yaml\")\n",
    "\n",
    "pipeline_args[\"enable_cache\"] = True\n",
    "\n",
    "run_args_train = {\n",
    "    \"num_epochs\": 1,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"eval_batch_size\": 64,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_seq_length\": 512,\n",
    "}\n",
    "\n",
    "# Use versioned artifacts from the last step\n",
    "# run_args_train[\"dataset_artifact_id\"] = latest_run.steps['tokenization_step'].output.id\n",
    "# run_args_train[\"tokenizer_artifact_id\"] = latest_run.steps['tokenizer_loader'].output.id\n",
    "\n",
    "# Configure the model\n",
    "pipeline_args[\"model_config\"] = model_config\n",
    "\n",
    "pipeline_args[\n",
    "    \"run_name\"\n",
    "] = f\"sentinment_analysis_training_run_{dt.now().strftime('%Y_%m_%d_%H_%M_%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96592299-0090-4d2a-962e-6ca232c1fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinment_analysis_training_pipeline.with_options(**pipeline_args)(\n",
    "    **run_args_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e29de-6d1b-41da-9ab2-ca2b32f1f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check out a new stack\n",
    "!zenml stack describe hf-sagemaker-airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a5bee-8465-4d41-888a-093f1f6a2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the stack\n",
    "!zenml stack set hf-sagemaker-airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3772c50-1c90-4ffc-8394-c9cfca16cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinment_analysis_training_pipeline.with_options(**pipeline_args)(\n",
    "    **run_args_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79f454-a45d-4f5f-aa93-330d52069124",
   "metadata": {},
   "source": [
    "## ü´Ö Step 3: Promote the model to production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a09b432-7a66-473e-bdb6-ffdca730498b",
   "metadata": {},
   "source": [
    "Following training, the automated promotion pipeline evaluates models against predefined metrics, identifying and marking the most performant one as 'Production ready'. This is another common use case for the Model Control Plane; we store the relevant metrics there to access them easily later.\n",
    "\n",
    "<img src=\"assets/promoting_pipeline_overview.png\" alt=\"Pipelines Trains\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac7ae5-70d0-449c-929c-e175c3062f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack set hf-sagemaker-local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c9ef6-4e6f-4e50-ac37-e05bef8570ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args_promoting = {}\n",
    "model_config = ModelConfig(name=zenml_model_name)\n",
    "pipeline_args[\"config_path\"] = os.path.join(\"configs\", \"promoting_config.yaml\")\n",
    "\n",
    "pipeline_args[\"model_config\"] = model_config\n",
    "\n",
    "pipeline_args[\n",
    "    \"run_name\"\n",
    "] = f\"sentinment_analysis_promoting_pipeline_run_{dt.now().strftime('%Y_%m_%d_%H_%M_%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df11e2-4591-4186-a8f8-243f9c4d1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinment_analysis_promote_pipeline.with_options(**pipeline_args)(\n",
    "    **run_args_promoting\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc4968-35fd-42e3-ba62-d8e1557aa0d6",
   "metadata": {},
   "source": [
    "## üíØ Step 4: Deploy the model to AWS Sagemaker Endpoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577aff86-bde9-48d4-9b52-209cfed9fd4e",
   "metadata": {},
   "source": [
    "This is the final step to automate the deployment of the slated production model to a Sagemaker endpoint. The deployment pipelines handles the complexities of AWS interactions and ensures that the model, along with its full history and context, is transitioned into a live environment ready for use. Here again we use the Model Control Plane interface to query the Huggingface revision and use that information to push to Huggingface Hub.\n",
    "\n",
    "<img src=\"assets/deploying_pipeline_overview.png\" alt=\"Pipelines Trains\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513ab5f-de05-4344-9d2c-fedbfbd21ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack set hf-sagemaker-local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ee4fc-f102-4b99-bdc3-2f1670c87679",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You just built two ML pipelines! You trained two models, evaluated them against\n",
    "a test set, registered the best one with the ZenML model control plane,\n",
    "and served some predictions. You also learned how to iterate on your models and\n",
    "data by using some of the ZenML utility abstractions. You saw how to view your\n",
    "artifacts and stacks via the CLI as well as the ZenML Dashboard.\n",
    "\n",
    "And that is just the tip of the iceberg of what ZenML can do; check out the [**docs**](https://docs.zenml.io/) to learn more\n",
    "about the capabilities of ZenML.\n",
    "\n",
    "## What to do now\n",
    "\n",
    "* If you have questions or feedback... join our [**Slack Community**](https://zenml.io/slack) and become part of the ZenML family!\n",
    "* If you want to try ZenML in a real-world setting... check out the [ZenML Cloud](https://cloud.zenml.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
