--- # GLOBAL PROMPT --------------------------------

project_name:
    type: str
    help: Short name for your project
    default: ZenML Starter
version:
    type: str
    help: |
        Version of your project
    default: "0.1.0"
open_source_license:
    type: str
    help: >-
        The license under which your project will be released
    choices:
        Apache Software License 2.0: apache
        MIT license: mit
        BSD license: bsd
        ISC license: isc
        GNU General Public License v3: gpl3
        Not open source: none
    default: apache
full_name:
    type: str
    help: >-
        The name of the person/entity holding the copyright
    default: ZenML GmbH
    when: "{{ open_source_license }}"
email:
    type: str
    help: >-
        The email of the person/entity holding the copyright
    default: info@zenml.io
    when: "{{ open_source_license }}"
auto_format:
    type: bool
    help: "Auto-format the generated code with black, ruff and autoflake? \n   (NOTE: you need to have these tools installed in your environment)"
    default: false

# SUB-TEMPLATE PROMPT [starter] ---------------------
use_step_params:
    type: bool
    help: "Would you like to see step parameters being used in the generated \n   ZenML steps?"
    default: true
    when: "{{ template == 'starter' }}"
use_custom_artifacts:
    type: bool
    help: "Would you like to see custom artifact data types and materializers \n   being used in the generated ZenML steps and pipelines?"
    default: true
    when: "{{ template == 'starter' }}"
configurable_dataset:
    type: bool
    help: "Would you like to be able to select the dataset used in model training\n   at runtime through the CLI and as a data loader step parameter?"
    default: true
    when: "{{ template == 'starter' and use_step_params }}"
sklearn_dataset_name:
    type: str
    help: "The generated ZenML project will be populated with some example code
    \n   featuring one of the UCI ML datasets from scikit-learn. \n   Which
    dataset would you like to see being used in the generated code?"
    choices:
        UCI Wine Data Set (classification): wine
        UCI Iris Data Set (classification): iris
        UCI Breast Cancer Wisconsin (Diagnostic) Data Set (classification): breast_cancer
    default: wine
    when: "{{ template == 'starter' }}"
configurable_model:
    type: bool
    help: "Would you like to be able to select the type of model used in model \n
    training at runtime through the CLI and as a model trainer step \n
    parameter?"
    default: true
    help: >-
        Would you like to be able to select the type of model used in model
        training at runtime through the CLI and as a model trainer step
        parameter ?
    default: true
    when: "{{ template == 'starter' and use_step_params }}"
sklearn_model_name:
    type: str
    help: "The generated ZenML project will be populated with some example code
    \n   featuring one of the scikit-learn classifier models. \n   Which model class would you like to see being used in the generated code?"
    choices:
        Logistic Regression: LogisticRegression
        C-Support Vector Classification: SVC
        Linear Support Vector Classification: LinearSVC
        Random Forest Classifier: RandomForestClassifier
        K-Nearest Neighbors Classifier: KNeighborsClassifier
        Gaussian Naive Bayes: GaussianNB
        Linear Perceptron Classifier: Perceptron
        Stochastic Gradient Descent Linear Classifier: SGDClassifier
        Decision Tree Classifier: DecisionTreeClassifier
    default: LogisticRegression
    when: "{{ template == 'starter' }}"

# CONFIGURATION -------------------------
_templates_suffix: ""
_subdirectory: "{{ template }}/template"
_exclude:
    - /README.md
_tasks:
    # Remove unused imports and variables
    - >-
      {% if _copier_conf.os == 'windows' %}
      echo "Auto-formatting not supported on Windows"
      {% else  %}
      {{ _copier_python }} -m ruff --select F401,F841 --fix \
          --exclude "__init__.py" --isolated \
          steps pipelines run.py > /dev/null 2>&1 || true
      {% endif %}
    # Sort imports
    - >-
      {% if _copier_conf.os == 'windows' %}
      echo "Auto-formatting not supported on Windows"
      {% else  %}
      {{ _copier_python }} -m ruff --select I \
          --fix --ignore D \
          steps pipelines run.py > /dev/null 2>&1 || true
      {% endif %}
    # Auto-format code
    - >-
      {% if _copier_conf.os == 'windows' %}
      echo "Auto-formatting not supported on Windows"
      {% else  %}
      {{ _copier_python }} -m black \
          --exclude '' --include '\.pyi?$' -l 79 \
          steps pipelines run.py > /dev/null 2>&1 || true
      {% endif %}
    - |
      echo "Congratulations, your project has been generated in the '{{ _copier_conf.dst_path }}' directory."
      echo "You can now run the following commands to get started:"
      echo "    cd {{ _copier_conf.dst_path }}"
      echo "    pip install -r requirements.txt"
      echo "    # Start the ZenML UI (optional; you'll also need the zenml[server] Python"
      echo "    # package installed"
      echo "    zenml up"
      echo "    python run.py"
      echo "Next, you should take a look at the '{{ _copier_conf.dst_path }}/README.md' file in the generated project."
      echo "Happy coding!"

_jinja_extensions:
    - jinja2_time.TimeExtension
